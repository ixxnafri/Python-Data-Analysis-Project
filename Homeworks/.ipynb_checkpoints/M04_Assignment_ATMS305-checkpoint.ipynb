{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATMS 305: Homework 4\n",
    "\n",
    "This assignment will be collected on October 3.\n",
    "\n",
    "## Rationale of this assignment\n",
    "\n",
    "One of the challenges of working with data is getting series lined up such that we can visualize them together, or perform statistical analysis on them so we can make predictive models using those data.\n",
    "\n",
    "In your folder, I have given you a file that contains \"normalized\" indicies of the Pacific Data Oscillation, the North Atlantic Oscillaion, and the El Niño Southern Oscillation.  These data were downloaded from https://www.esrl.noaa.gov/psd/data/correlation/pdo.data.  These data are normalized such that the mean of the index is 0, and one standard deviation away from the mean is a value of 1 or -1 depending on the sign of the anomaly.  For example, in the El Niño index, a value of +1 is a value 1 standard deviation away from the mean.  We will discuss what this means quantitatively in future lectures, but between -1 and +1 in an index normalized in this way, approximately 68% of the data points fall within this range of values.  This normalization method provides a convenient way to compare data using probabilities rather than physical units (for example Sea Surface Temperature in degrees Celsius), which may have different ranges of values.\n",
    "\n",
    "### Information about these files\n",
    "These files are formatted in *fixed width format*, so `pd.read_table` will be the tool we will use here (`pd.read_csv` is for comma or space-delimited files), and there is some header and footer information.  You will have to use the `skipheader` and `skipfooter` keywords in `pd.read_table`, read http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html for documentation on how to use this function. \n",
    "\n",
    "In the data section the rows are the values of the index by year, and the columns are the month of year (January-December).  Missing values are given by the value in the row following the data table.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 1\n",
    "\n",
    "a) Load the ENSO file `censo.data` using `pd.read_table`.  You'll need to take a look at the file to determine keywords such as `skipheader` and `skipfooter`. Print out the number of data months in the dataset (rows x columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Create a new data frame called `enso_tser` where there is only one data column.  You can use `df.drop([colname],axis=1)` to get rid of column 1, and then `df.stack()` to reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1     0.26\n",
       "    2     0.43\n",
       "    3     0.72\n",
       "    4     0.21\n",
       "    5     0.24\n",
       "    6     0.41\n",
       "    7     0.08\n",
       "    8     0.25\n",
       "    9     0.45\n",
       "    10   -0.64\n",
       "    11   -0.21\n",
       "    12    0.58\n",
       "1   1     0.18\n",
       "    2     0.13\n",
       "    3    -0.55\n",
       "    4     0.15\n",
       "    5     0.43\n",
       "    6     0.00\n",
       "    7    -0.06\n",
       "    8     0.08\n",
       "    9    -0.42\n",
       "    10   -0.59\n",
       "    11   -0.29\n",
       "    12   -0.91\n",
       "2   1    -0.74\n",
       "    2    -1.70\n",
       "    3    -1.43\n",
       "    4    -1.29\n",
       "    5    -1.22\n",
       "    6    -1.69\n",
       "          ... \n",
       "66  7     0.42\n",
       "    8     0.70\n",
       "    9     0.97\n",
       "    10    0.76\n",
       "    11    1.24\n",
       "    12    0.87\n",
       "67  1     0.94\n",
       "    2     0.14\n",
       "    3     0.91\n",
       "    4     0.83\n",
       "    5     1.69\n",
       "    6     1.53\n",
       "    7     2.34\n",
       "    8     2.60\n",
       "    9     2.92\n",
       "    10    2.77\n",
       "    11    1.99\n",
       "    12    1.91\n",
       "68  1     2.96\n",
       "    2     3.05\n",
       "    3     1.23\n",
       "    4     1.78\n",
       "    5     0.07\n",
       "    6    -0.40\n",
       "    7    -0.56\n",
       "    8    -0.93\n",
       "    9    -1.25\n",
       "    10   -0.25\n",
       "    11   -0.14\n",
       "    12   -0.39\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Use `pd.date_range` to create a column `time`, which is in datetime format, that corresponds to the time in the data file.  Set the index of the time series to `time` using `df.set_index(\"time\", inplace=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Repeat for all 3 of the data files, and save the files to csv format using `pd.to_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "a) Read in all of the data in problem 1, and combine all of the data into one large pandas dataframe, with each index labeled with the index you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Create a python code that creates a \"contingency table\" that has rows containing the frequency of positive and negative anomalies for each of the index values related to each other.\n",
    "\n",
    "For example:\n",
    "```\n",
    "       | PDO + | PDO - |\n",
    "ENSO + | # mos | # mos |\n",
    "ENSO - | # mos | # mos | \n",
    "```\n",
    "\n",
    "Use the resources here to help solve the problem:\n",
    "\n",
    "http://stackoverflow.com/questions/29901436/is-there-a-pythonic-way-to-do-a-contingency-table-in-pandas\n",
    "\n",
    "http://chrisalbon.com/python/pandas_crosstabs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
