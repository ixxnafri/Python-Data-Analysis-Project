{"type":"settings","kernel":"python3","backend_state":"running","trust":true,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"kernel_state":"idle"}
{"type":"file","last_load":1505981205202}
{"type":"cell","id":"be0a46","pos":2,"input":"<h3>Reading In Files</h3>","cell_type":"markdown"}
{"type":"cell","id":"2d796e","pos":4,"input":"# Converting dates to times for plotting is non-trivial. Unix epoch: January 1, 1970, or since\n# the beginning of your data.  There is no absolute time without reasonably sized integers.\n\nfrom datetime import datetime\n\nwith open(\"mlo_station_data_set/weekly_in_situ_co2_mlo.csv\",\"r\") as file:\n    raw_data = file.readlines()\n\ndata = []\n\nfor line in raw_data:\n    if line[0] != '\"':\n        line = line.rstrip('\\n').split(',')\n        t = [int(x) for x in line[0].split('-')]\n        line[0] = int((datetime(t[0],t[1],t[2])-datetime(1958,1,1)).total_seconds())\n        line[1] = float(line[1])\n        data.append(line)\n\nfile.close()\nprint(data)\n#you can convert python lists to ndarrays with np.array()","output":{"0":{"name":"stderr","output_type":"stream","text":"WARNING: Some output was deleted.\n"}},"cell_type":"code","exec_count":2,"scrolled":true}
{"type":"cell","id":"d19ab6","pos":8,"input":"# 2. Numerical Python (NumPy) Functions  (np.loadtxt() is for when there is no missing data.)\nimport numpy as np\nimport io\nfrom datetime import datetime\n\ns = io.BytesIO(open('mlo_station_data_set/weekly_in_situ_co2_mlo.csv','rb').read().replace(b'-',b','))\nconv = lambda t: (datetime(t[0],t[1],t[2])-datetime(1958,1,1)).total_seconds()\nfile = np.genfromtxt(s, delimiter=',', comments='\"', dtype=[('Year','i4'),('Month','i2'),('Day','i2'),('CO2','f8')])\n\n# Convert Year, Month and Day to seconds from January 1, 1958\n\ndata = np.zeros([np.size(file),2])\n\nfor line in range(np.size(file)):\n    line_1 = (datetime(file['Year'][line],file['Month'][line],file['Day'][line])-datetime(1958,1,1)).total_seconds()\n    line_2 = file['CO2'][line]\n    data[line] = [line_1,line_2]\n\nprint(np.shape(data))    \n    \n\n\n\n\n","output":{"0":{"name":"stdout","output_type":"stream","text":"(3026, 2)\n"}},"cell_type":"code","exec_count":4}
{"type":"cell","id":"0cab8f","pos":10,"input":"import numpy as np\nfname = 'weekly_co2_ppm_numpy-ex'\nnp.savetxt(fname, data, fmt='%.5e', delimiter=',', newline='\\n') \n# Other options: header='', footer='', comments='# ')","cell_type":"code","exec_count":5,"collapsed":true}
{"type":"cell","id":"7e5cc9","pos":11,"input":"<h2>#3 I/O with Pandas (Pan[el] Da[ta])</h2>\n<p><a href=\"https://pandas.pydata.org/index.html\">Pandas</a> is a powerful python package for data analysis that greatly simplifies I/O handling. Wes McKinney started developing the package in 2008, with Chang She joining in 2012, followed by additional core contributors. For more on I/O visit: https://pandas.pydata.org/pandas-docs/stable/io.html </p>","cell_type":"markdown"}
{"type":"cell","id":"0ebcb7","pos":16,"input":"","cell_type":"markdown"}
{"type":"cell","id":"c8008d","pos":12,"input":"# 3. Using pandas to create Data Structures \n\nimport pandas as pd\nfilename = 'mlo_station_data_set/weekly_in_situ_co2_mlo.csv'\ndata = pd.read_csv(filename, comment='\"',)\ndata.columns = ['dates', 'co2_ppm']\ndata['dates'] = pd.to_datetime(data['dates'])\ndata.index = data['dates'] # A critical step for using resampling\nprint(data)\n# Input is EASY, but computation is easier! Group data by year and compute the mean. Other functions: count(), sum(), median(), cumsum() etc. \ndf2 = data.resample('A').mean()\ndf2","output":{"0":{"name":"stdout","output_type":"stream","text":"                dates  co2_ppm\ndates                         \n1958-04-05 1958-04-05   317.31\n1958-04-12 1958-04-12   317.69\n1958-04-19 1958-04-19   317.58\n1958-04-26 1958-04-26   316.48\n1958-05-03 1958-05-03   316.95\n1958-05-17 1958-05-17   317.56\n1958-05-24 1958-05-24   317.99\n1958-07-05 1958-07-05   315.85\n1958-07-12 1958-07-12   315.85\n1958-07-19 1958-07-19   315.46\n1958-07-26 1958-07-26   315.59\n1958-08-02 1958-08-02   315.64\n1958-08-09 1958-08-09   315.10\n1958-08-16 1958-08-16   315.09\n1958-08-30 1958-08-30   314.14\n1958-09-06 1958-09-06   313.54\n1958-11-08 1958-11-08   313.05\n1958-11-15 1958-11-15   313.26\n1958-11-22 1958-11-22   313.57\n1958-11-29 1958-11-29   314.01\n1958-12-06 1958-12-06   314.56\n1958-12-13 1958-12-13   314.41\n1958-12-20 1958-12-20   314.77\n1958-12-27 1958-12-27   315.21\n1959-01-03 1959-01-03   315.24\n1959-01-10 1959-01-10   315.50\n1959-01-17 1959-01-17   315.69\n1959-01-24 1959-01-24   315.86\n1959-01-31 1959-01-31   315.42\n1959-02-14 1959-02-14   316.94\n...               ...      ...\n2017-01-07 2017-01-07   405.94\n2017-01-14 2017-01-14   405.91\n2017-01-21 2017-01-21   406.37\n2017-01-28 2017-01-28   406.35\n2017-02-04 2017-02-04   406.20\n2017-02-11 2017-02-11   406.02\n2017-02-18 2017-02-18   406.17\n2017-02-25 2017-02-25   408.07\n2017-03-04 2017-03-04   407.06\n2017-03-11 2017-03-11   406.53\n2017-03-18 2017-03-18   406.73\n2017-03-25 2017-03-25   407.89\n2017-04-01 2017-04-01   408.66\n2017-04-08 2017-04-08   407.19\n2017-04-15 2017-04-15   409.12\n2017-04-22 2017-04-22   409.89\n2017-04-29 2017-04-29   409.04\n2017-05-06 2017-05-06   409.54\n2017-05-13 2017-05-13   409.83\n2017-05-20 2017-05-20   410.18\n2017-05-27 2017-05-27   409.88\n2017-06-03 2017-06-03   409.67\n2017-06-10 2017-06-10   409.62\n2017-06-17 2017-06-17   408.82\n2017-06-24 2017-06-24   408.43\n2017-07-01 2017-07-01   407.77\n2017-07-08 2017-07-08   407.56\n2017-07-15 2017-07-15   407.11\n2017-07-22 2017-07-22   406.76\n2017-07-29 2017-07-29   406.92\n\n[3025 rows x 2 columns]\n"},"1":{"data":{"text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>co2_ppm</th>\n    </tr>\n    <tr>\n      <th>dates</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1958-12-31</th>\n      <td>315.444167</td>\n    </tr>\n    <tr>\n      <th>1959-12-31</th>\n      <td>315.945417</td>\n    </tr>\n    <tr>\n      <th>1960-12-31</th>\n      <td>316.898868</td>\n    </tr>\n    <tr>\n      <th>1961-12-31</th>\n      <td>317.634038</td>\n    </tr>\n    <tr>\n      <th>1962-12-31</th>\n      <td>318.597708</td>\n    </tr>\n    <tr>\n      <th>1963-12-31</th>\n      <td>318.953673</td>\n    </tr>\n    <tr>\n      <th>1964-12-31</th>\n      <td>318.617097</td>\n    </tr>\n    <tr>\n      <th>1965-12-31</th>\n      <td>320.033462</td>\n    </tr>\n    <tr>\n      <th>1966-12-31</th>\n      <td>321.363061</td>\n    </tr>\n    <tr>\n      <th>1967-12-31</th>\n      <td>322.168800</td>\n    </tr>\n    <tr>\n      <th>1968-12-31</th>\n      <td>323.054423</td>\n    </tr>\n    <tr>\n      <th>1969-12-31</th>\n      <td>324.620769</td>\n    </tr>\n    <tr>\n      <th>1970-12-31</th>\n      <td>325.675769</td>\n    </tr>\n    <tr>\n      <th>1971-12-31</th>\n      <td>326.316346</td>\n    </tr>\n    <tr>\n      <th>1972-12-31</th>\n      <td>327.463962</td>\n    </tr>\n    <tr>\n      <th>1973-12-31</th>\n      <td>329.681346</td>\n    </tr>\n    <tr>\n      <th>1974-12-31</th>\n      <td>330.252308</td>\n    </tr>\n    <tr>\n      <th>1975-12-31</th>\n      <td>331.142885</td>\n    </tr>\n    <tr>\n      <th>1976-12-31</th>\n      <td>332.112353</td>\n    </tr>\n    <tr>\n      <th>1977-12-31</th>\n      <td>333.907547</td>\n    </tr>\n    <tr>\n      <th>1978-12-31</th>\n      <td>335.531154</td>\n    </tr>\n    <tr>\n      <th>1979-12-31</th>\n      <td>336.864423</td>\n    </tr>\n    <tr>\n      <th>1980-12-31</th>\n      <td>338.691731</td>\n    </tr>\n    <tr>\n      <th>1981-12-31</th>\n      <td>339.910769</td>\n    </tr>\n    <tr>\n      <th>1982-12-31</th>\n      <td>341.111923</td>\n    </tr>\n    <tr>\n      <th>1983-12-31</th>\n      <td>342.768679</td>\n    </tr>\n    <tr>\n      <th>1984-12-31</th>\n      <td>344.237083</td>\n    </tr>\n    <tr>\n      <th>1985-12-31</th>\n      <td>345.917451</td>\n    </tr>\n    <tr>\n      <th>1986-12-31</th>\n      <td>347.134808</td>\n    </tr>\n    <tr>\n      <th>1987-12-31</th>\n      <td>348.930000</td>\n    </tr>\n    <tr>\n      <th>1988-12-31</th>\n      <td>351.482453</td>\n    </tr>\n    <tr>\n      <th>1989-12-31</th>\n      <td>352.922308</td>\n    </tr>\n    <tr>\n      <th>1990-12-31</th>\n      <td>354.190000</td>\n    </tr>\n    <tr>\n      <th>1991-12-31</th>\n      <td>355.607885</td>\n    </tr>\n    <tr>\n      <th>1992-12-31</th>\n      <td>356.375000</td>\n    </tr>\n    <tr>\n      <th>1993-12-31</th>\n      <td>357.047885</td>\n    </tr>\n    <tr>\n      <th>1994-12-31</th>\n      <td>358.895283</td>\n    </tr>\n    <tr>\n      <th>1995-12-31</th>\n      <td>360.891923</td>\n    </tr>\n    <tr>\n      <th>1996-12-31</th>\n      <td>362.650000</td>\n    </tr>\n    <tr>\n      <th>1997-12-31</th>\n      <td>363.772500</td>\n    </tr>\n    <tr>\n      <th>1998-12-31</th>\n      <td>366.623462</td>\n    </tr>\n    <tr>\n      <th>1999-12-31</th>\n      <td>368.294231</td>\n    </tr>\n    <tr>\n      <th>2000-12-31</th>\n      <td>369.477736</td>\n    </tr>\n    <tr>\n      <th>2001-12-31</th>\n      <td>371.030769</td>\n    </tr>\n    <tr>\n      <th>2002-12-31</th>\n      <td>373.082115</td>\n    </tr>\n    <tr>\n      <th>2003-12-31</th>\n      <td>375.680816</td>\n    </tr>\n    <tr>\n      <th>2004-12-31</th>\n      <td>377.362500</td>\n    </tr>\n    <tr>\n      <th>2005-12-31</th>\n      <td>379.577551</td>\n    </tr>\n    <tr>\n      <th>2006-12-31</th>\n      <td>381.797200</td>\n    </tr>\n    <tr>\n      <th>2007-12-31</th>\n      <td>383.602549</td>\n    </tr>\n    <tr>\n      <th>2008-12-31</th>\n      <td>385.432500</td>\n    </tr>\n    <tr>\n      <th>2009-12-31</th>\n      <td>387.363269</td>\n    </tr>\n    <tr>\n      <th>2010-12-31</th>\n      <td>389.876346</td>\n    </tr>\n    <tr>\n      <th>2011-12-31</th>\n      <td>391.649434</td>\n    </tr>\n    <tr>\n      <th>2012-12-31</th>\n      <td>394.003800</td>\n    </tr>\n    <tr>\n      <th>2013-12-31</th>\n      <td>396.560769</td>\n    </tr>\n    <tr>\n      <th>2014-12-31</th>\n      <td>398.610385</td>\n    </tr>\n    <tr>\n      <th>2015-12-31</th>\n      <td>400.877885</td>\n    </tr>\n    <tr>\n      <th>2016-12-31</th>\n      <td>404.276415</td>\n    </tr>\n    <tr>\n      <th>2017-12-31</th>\n      <td>407.841000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"output_type":"execute_result","exec_count":1}},"cell_type":"code","exec_count":1}
{"type":"cell","id":"539215","pos":0,"input":"<h1>Module 3: Python IO</h1>\n\n<h2>Part A: File Input/Output</h2>\n<p>Data available at\nhttp://scrippsco2.ucsd.edu/data/atmospheric_co2/sampling_stations</p>","cell_type":"markdown"}
{"type":"cell","id":"e07feb","pos":18,"input":"","cell_type":"code","exec_count":0}
{"type":"cell","id":"752f9a","pos":1,"input":"<h2>#1 I/O with Python Built-In Functions</h2>\n<p>There are several different ways read files in python. <em>Caveat emptor</em>- The less input/code you provide, the more careful you need to be in evaluating your results.</p>\n<p>Here are some helpful resources on using the \"Built-In\" open/read/write/close functions: <br> \nhttps://docs.python.org/3/library/functions.html,<br> https://docs.python.org/3/tutorial/inputoutput.html,<br> http://www.pythonforbeginners.com/files/reading-and-writing-files-in-python.</p>","cell_type":"markdown"}
{"type":"cell","id":"482286","pos":9,"input":"<h3>Writing Files with NumPy</h3>\n<p>You can save files as either a binary file in numpy format, (extension .npy), or as a text file. Your choice will depend on the task at hand.  Here will work work with text files.</p>","cell_type":"markdown"}
{"type":"cell","id":"519d58","pos":7,"input":"<h2>#2 I/O with Numerical Python (NumPy) Functions</h2>\n<p>Here is a direct link to NumPy I/O functions https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.io.html</p>\n<h3>Reading in Files as NumPy Arrays</h3>","cell_type":"markdown"}
{"type":"cell","id":"4aec62","pos":5,"input":"<h3>Writing Files</h3>","cell_type":"markdown"}
{"type":"cell","id":"79655f","pos":3,"input":"# Different ways to read in files\n\n#Open the file\nfile = open(\"mlo_station_data_set/weekly_in_situ_co2_mlo.csv\",\"r\")\n\n#Read each line of the file, alternate methods are list(f) and f.readlines()\nfor line in file:\n     print(line, end='')\n\n# Aternatives:\n#print(list(file))\n#print(file.readlines())\n\n\n#Close the file, closing the file after reading and/or writing is a programming best practice.        \nfile.close()\n\n","output":{"0":{"name":"stderr","output_type":"stream","text":"WARNING: Some output was deleted.\n"}},"cell_type":"code","exec_count":1,"scrolled":true}
{"type":"cell","id":"53def3","pos":13,"input":"<h3>Pandas Grouping Options</h3>\n<p>There are many options for grouping. You can learn more about them in <a href=\"http://pandas.pydata.org/pandas-docs/stable/timeseries.html\">Pandas's timeseries docs </a>. They are also listed them below for your convience.</p>\n\n|  Value  |  Description  |\n|---------|:-------------:|\n|B | business day frequency | \n|C | custom business day frequency (experimental) |\n|D | calendar day frequency |\n|W | weekly frequency |\n|M | month end frequency |\n|BM | business month end frequency |\n|CBM | custom business month end frequency |\n|MS | month start frequency |\n|BMS | business month start frequency |\n|CBMS| custom business month start frequency |\n|Q | quarter end frequency |\n|BQ | business quarter endfrequency |\n|QS | quarter start frequency |\n|BQS | business quarter start frequency |\n|A | year end frequency |\n|BA | business year end frequency |\n|AS | year start frequency |\n|BAS | business year start frequency |\n|BH | business hour frequency |\n|H | hourly frequency |\n|T | minutely frequency |\n|S | secondly frequency |\n|L | milliseonds |\n|U | microseconds |\n|N | nanoseconds |\n\n\n<h3>Pandas Resampling Method Options</h3>\n<p>There are many methods you can apply on pandas dataframes. A non-comprehensive listed them below for your convience.</p>\n\n|  Method  |   Description   |\n|----------|:---------------:|\n| bfill | Backward fill |\n| count | Count of values |\n| ffill | Forward fill |\n| first | First valid data value |\n| last | Last valid data value |\n| max | Maximum data value |\n| mean | Mean of values in time range |\n| median | Median of values in time range |\n| min | Minimum data value |\n| nunique | Number of unique values |\n| ohlc | Opening value, highest value, lowest value, closing value |\n| pad | Same as forward fill |\n| std | Standard deviation of values |\n| sum | Sum of values |\n| var | Variance of values |","cell_type":"markdown"}
{"type":"cell","id":"5deba5","pos":6,"input":"file = open('weekly_co2_builtin-ex.txt', 'w')\n\nfor line in data:\n    file.write(str(line).lstrip('[').rstrip(']')+\"\\n\") \n\nfile.close()","cell_type":"code","exec_count":3}
{"type":"cell","id":"300334","pos":15,"input":"#Be careful as you write out functions- do not overwrite your original data.\ndf2.to_csv('mlo_station_data_set/average_annual_co2.csv')\n\n#pandas.DataFrame.to_csv(path_or_buf=None, sep=', ', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal='.')\n\n","cell_type":"code","exec_count":16}
{"type":"cell","id":"ec257e","pos":17,"input":"import pandas as pd\nfname = 'geneds_json.txt'\ndata = pd.read_json(fname)\ns = data.apply(lambda x: pd.Series(x['GenedRequirement']),axis=1).stack().reset_index(level=1, drop=True)\nprint(s)\ns.name = 'GenedRequirement'\nnew = data.drop('GenedRequirement', axis=1).join(s)\nnew.groupby(['GenedRequirement']).mean()","output":{"0":{"name":"stdout","output_type":"stream","text":"0      Natural Science & Technology\n1      Social & Behavioral Sciences\n2      Natural Science & Technology\n3            Quantitative Reasoning\n4            Quantitative Reasoning\n5             Humanities & the Arts\n6      Social & Behavioral Sciences\n7            Quantitative Reasoning\n8      Natural Science & Technology\n8            Quantitative Reasoning\n9      Natural Science & Technology\n9            Quantitative Reasoning\n10     Natural Science & Technology\n11     Natural Science & Technology\n12     Social & Behavioral Sciences\n13           Quantitative Reasoning\n14           Quantitative Reasoning\n15     Natural Science & Technology\n16     Natural Science & Technology\n17           Quantitative Reasoning\n18     Natural Science & Technology\n19     Social & Behavioral Sciences\n20     Natural Science & Technology\n20           Quantitative Reasoning\n21     Natural Science & Technology\n21           Quantitative Reasoning\n22           Quantitative Reasoning\n23           Quantitative Reasoning\n24           Quantitative Reasoning\n25     Natural Science & Technology\n                   ...             \n469            Advanced Composition\n470             Non-Western Culture\n470          Quantitative Reasoning\n470    Social & Behavioral Sciences\n471           Humanities & the Arts\n472     Western/Comparative Culture\n472           Humanities & the Arts\n473           Humanities & the Arts\n474             Non-Western Culture\n474           Humanities & the Arts\n475          Quantitative Reasoning\n476            Advanced Composition\n477     Western/Comparative Culture\n477           Humanities & the Arts\n478     Western/Comparative Culture\n478           Humanities & the Arts\n479            Advanced Composition\n480     Western/Comparative Culture\n480           Humanities & the Arts\n481           Humanities & the Arts\n482           Humanities & the Arts\n483    Social & Behavioral Sciences\n484             Non-Western Culture\n484           Humanities & the Arts\n485            Advanced Composition\n485     Western/Comparative Culture\n485           Humanities & the Arts\n486    Social & Behavioral Sciences\n487     Western/Comparative Culture\n487           Humanities & the Arts\nLength: 698, dtype: object\n"},"1":{"data":{"text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>avg_gpa</th>\n      <th>compre</th>\n      <th>pct_As</th>\n    </tr>\n    <tr>\n      <th>GenedRequirement</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Advanced Composition</th>\n      <td>245.058824</td>\n      <td>3.422309</td>\n      <td>0.640070</td>\n      <td>0.424564</td>\n    </tr>\n    <tr>\n      <th>Humanities &amp; the Arts</th>\n      <td>224.790323</td>\n      <td>3.357140</td>\n      <td>0.613929</td>\n      <td>0.388573</td>\n    </tr>\n    <tr>\n      <th>Natural Science &amp; Technology</th>\n      <td>1355.483871</td>\n      <td>3.169332</td>\n      <td>0.588273</td>\n      <td>0.384213</td>\n    </tr>\n    <tr>\n      <th>Non-Western Culture</th>\n      <td>216.828571</td>\n      <td>3.377348</td>\n      <td>0.632288</td>\n      <td>0.420239</td>\n    </tr>\n    <tr>\n      <th>Quantitative Reasoning</th>\n      <td>1254.686567</td>\n      <td>3.087739</td>\n      <td>0.554821</td>\n      <td>0.337707</td>\n    </tr>\n    <tr>\n      <th>Social &amp; Behavioral Sciences</th>\n      <td>599.099099</td>\n      <td>3.333429</td>\n      <td>0.630614</td>\n      <td>0.427871</td>\n    </tr>\n    <tr>\n      <th>Western/Comparative Culture</th>\n      <td>292.858586</td>\n      <td>3.365834</td>\n      <td>0.625333</td>\n      <td>0.409208</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"output_type":"execute_result","exec_count":19}},"cell_type":"code","exec_count":19}
{"type":"cell","id":"8ccea4","pos":14,"input":"<h3>Writing Files with Pandas</h3>\nHere is the documentation for writing a csv file, locate the documentation for a json file on your own. https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n    ","cell_type":"markdown"}
{"output":{"0":{"text":"Trump hair!\n","name":"stdout"}},"exec_count":3,"start":1506431271290,"input":"test = \"Donald Trump has great hair!\"\n\nprint(test[7:13]+test[23:])","state":"done","pos":10.5,"type":"cell","end":1506431271307,"id":"21d181","kernel":"python3"}