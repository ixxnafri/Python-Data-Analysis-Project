{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Module 3: Python IO</h1>\n",
    "\n",
    "<h2>Part A: File Input/Output</h2>\n",
    "<p>Data available at\n",
    "http://scrippsco2.ucsd.edu/data/atmospheric_co2/sampling_stations</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>#1 I/O with Python Built-In Functions</h2>\n",
    "<p>There are several different ways read files in python. <em>Caveat emptor</em>- The less input/code you provide, the more careful you need to be in evaluating your results.</p>\n",
    "<p>Here are some helpful resources on using the \"Built-In\" open/read/write/close functions: <br> \n",
    "https://docs.python.org/3/library/functions.html,<br> https://docs.python.org/3/tutorial/inputoutput.html,<br> http://www.pythonforbeginners.com/files/reading-and-writing-files-in-python.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading In Files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Some output was deleted.\n"
     ]
    }
   ],
   "source": [
    "# Different ways to read in files\n",
    "\n",
    "#Open the file\n",
    "file = open(\"mlo_station_data_set/weekly_in_situ_co2_mlo.csv\",\"r\")\n",
    "\n",
    "#Read each line of the file, alternate methods are list(f) and f.readlines()\n",
    "for line in file:\n",
    "     print(line, end='')\n",
    "\n",
    "# Aternatives:\n",
    "#print(list(file))\n",
    "#print(file.readlines())\n",
    "\n",
    "\n",
    "#Close the file, closing the file after reading and/or writing is a programming best practice.        \n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Some output was deleted.\n"
     ]
    }
   ],
   "source": [
    "# Converting dates to times for plotting is non-trivial. Unix epoch: January 1, 1970, or since\n",
    "# the beginning of your data.  There is no absolute time without reasonably sized integers.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "with open(\"mlo_station_data_set/weekly_in_situ_co2_mlo.csv\",\"r\") as file:\n",
    "    raw_data = file.readlines()\n",
    "\n",
    "data = []\n",
    "\n",
    "for line in raw_data:\n",
    "    if line[0] != '\"':\n",
    "        line = line.rstrip('\\n').split(',')\n",
    "        t = [int(x) for x in line[0].split('-')]\n",
    "        line[0] = int((datetime(t[0],t[1],t[2])-datetime(1958,1,1)).total_seconds())\n",
    "        line[1] = float(line[1])\n",
    "        data.append(line)\n",
    "\n",
    "file.close()\n",
    "print(data)\n",
    "#you can convert python lists to ndarrays with np.array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Writing Files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('weekly_co2_builtin-ex.txt', 'w')\n",
    "\n",
    "for line in data:\n",
    "    file.write(str(line).lstrip('[').rstrip(']')+\"\\n\") \n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>#2 I/O with Numerical Python (NumPy) Functions</h2>\n",
    "<p>Here is a direct link to NumPy I/O functions https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.io.html</p>\n",
    "<h3>Reading in Files as NumPy Arrays</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3026, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2. Numerical Python (NumPy) Functions  (np.loadtxt() is for when there is no missing data.)\n",
    "import numpy as np\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "s = io.BytesIO(open('mlo_station_data_set/weekly_in_situ_co2_mlo.csv','rb').read().replace(b'-',b','))\n",
    "conv = lambda t: (datetime(t[0],t[1],t[2])-datetime(1958,1,1)).total_seconds()\n",
    "file = np.genfromtxt(s, delimiter=',', comments='\"', dtype=[('Year','i4'),('Month','i2'),('Day','i2'),('CO2','f8')])\n",
    "\n",
    "# Convert Year, Month and Day to seconds from January 1, 1958\n",
    "\n",
    "data = np.zeros([np.size(file),2])\n",
    "\n",
    "for line in range(np.size(file)):\n",
    "    line_1 = (datetime(file['Year'][line],file['Month'][line],file['Day'][line])-datetime(1958,1,1)).total_seconds()\n",
    "    line_2 = file['CO2'][line]\n",
    "    data[line] = [line_1,line_2]\n",
    "\n",
    "print(np.shape(data))    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Writing Files with NumPy</h3>\n",
    "<p>You can save files as either a binary file in numpy format, (extension .npy), or as a text file. Your choice will depend on the task at hand.  Here will work work with text files.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fname = 'weekly_co2_ppm_numpy-ex'\n",
    "np.savetxt(fname, data, fmt='%.5e', delimiter=',', newline='\\n') \n",
    "# Other options: header='', footer='', comments='# ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump hair!\n"
     ]
    }
   ],
   "source": [
    "test = \"Donald Trump has great hair!\"\n",
    "\n",
    "print(test[7:13]+test[23:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>#3 I/O with Pandas (Pan[el] Da[ta])</h2>\n",
    "<p><a href=\"https://pandas.pydata.org/index.html\">Pandas</a> is a powerful python package for data analysis that greatly simplifies I/O handling. Wes McKinney started developing the package in 2008, with Chang She joining in 2012, followed by additional core contributors. For more on I/O visit: https://pandas.pydata.org/pandas-docs/stable/io.html </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                dates  co2_ppm\n",
      "dates                         \n",
      "1958-04-05 1958-04-05   317.31\n",
      "1958-04-12 1958-04-12   317.69\n",
      "1958-04-19 1958-04-19   317.58\n",
      "1958-04-26 1958-04-26   316.48\n",
      "1958-05-03 1958-05-03   316.95\n",
      "1958-05-17 1958-05-17   317.56\n",
      "1958-05-24 1958-05-24   317.99\n",
      "1958-07-05 1958-07-05   315.85\n",
      "1958-07-12 1958-07-12   315.85\n",
      "1958-07-19 1958-07-19   315.46\n",
      "1958-07-26 1958-07-26   315.59\n",
      "1958-08-02 1958-08-02   315.64\n",
      "1958-08-09 1958-08-09   315.10\n",
      "1958-08-16 1958-08-16   315.09\n",
      "1958-08-30 1958-08-30   314.14\n",
      "1958-09-06 1958-09-06   313.54\n",
      "1958-11-08 1958-11-08   313.05\n",
      "1958-11-15 1958-11-15   313.26\n",
      "1958-11-22 1958-11-22   313.57\n",
      "1958-11-29 1958-11-29   314.01\n",
      "1958-12-06 1958-12-06   314.56\n",
      "1958-12-13 1958-12-13   314.41\n",
      "1958-12-20 1958-12-20   314.77\n",
      "1958-12-27 1958-12-27   315.21\n",
      "1959-01-03 1959-01-03   315.24\n",
      "1959-01-10 1959-01-10   315.50\n",
      "1959-01-17 1959-01-17   315.69\n",
      "1959-01-24 1959-01-24   315.86\n",
      "1959-01-31 1959-01-31   315.42\n",
      "1959-02-14 1959-02-14   316.94\n",
      "...               ...      ...\n",
      "2017-01-07 2017-01-07   405.94\n",
      "2017-01-14 2017-01-14   405.91\n",
      "2017-01-21 2017-01-21   406.37\n",
      "2017-01-28 2017-01-28   406.35\n",
      "2017-02-04 2017-02-04   406.20\n",
      "2017-02-11 2017-02-11   406.02\n",
      "2017-02-18 2017-02-18   406.17\n",
      "2017-02-25 2017-02-25   408.07\n",
      "2017-03-04 2017-03-04   407.06\n",
      "2017-03-11 2017-03-11   406.53\n",
      "2017-03-18 2017-03-18   406.73\n",
      "2017-03-25 2017-03-25   407.89\n",
      "2017-04-01 2017-04-01   408.66\n",
      "2017-04-08 2017-04-08   407.19\n",
      "2017-04-15 2017-04-15   409.12\n",
      "2017-04-22 2017-04-22   409.89\n",
      "2017-04-29 2017-04-29   409.04\n",
      "2017-05-06 2017-05-06   409.54\n",
      "2017-05-13 2017-05-13   409.83\n",
      "2017-05-20 2017-05-20   410.18\n",
      "2017-05-27 2017-05-27   409.88\n",
      "2017-06-03 2017-06-03   409.67\n",
      "2017-06-10 2017-06-10   409.62\n",
      "2017-06-17 2017-06-17   408.82\n",
      "2017-06-24 2017-06-24   408.43\n",
      "2017-07-01 2017-07-01   407.77\n",
      "2017-07-08 2017-07-08   407.56\n",
      "2017-07-15 2017-07-15   407.11\n",
      "2017-07-22 2017-07-22   406.76\n",
      "2017-07-29 2017-07-29   406.92\n",
      "\n",
      "[3025 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2_ppm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1958-12-31</th>\n",
       "      <td>315.444167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-12-31</th>\n",
       "      <td>315.945417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-12-31</th>\n",
       "      <td>316.898868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-12-31</th>\n",
       "      <td>317.634038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-31</th>\n",
       "      <td>318.597708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-12-31</th>\n",
       "      <td>318.953673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-12-31</th>\n",
       "      <td>318.617097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-12-31</th>\n",
       "      <td>320.033462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966-12-31</th>\n",
       "      <td>321.363061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967-12-31</th>\n",
       "      <td>322.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968-12-31</th>\n",
       "      <td>323.054423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-12-31</th>\n",
       "      <td>324.620769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-12-31</th>\n",
       "      <td>325.675769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-12-31</th>\n",
       "      <td>326.316346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972-12-31</th>\n",
       "      <td>327.463962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973-12-31</th>\n",
       "      <td>329.681346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974-12-31</th>\n",
       "      <td>330.252308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-12-31</th>\n",
       "      <td>331.142885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-12-31</th>\n",
       "      <td>332.112353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977-12-31</th>\n",
       "      <td>333.907547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978-12-31</th>\n",
       "      <td>335.531154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-12-31</th>\n",
       "      <td>336.864423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-31</th>\n",
       "      <td>338.691731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-12-31</th>\n",
       "      <td>339.910769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-12-31</th>\n",
       "      <td>341.111923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-12-31</th>\n",
       "      <td>342.768679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-12-31</th>\n",
       "      <td>344.237083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-12-31</th>\n",
       "      <td>345.917451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-12-31</th>\n",
       "      <td>347.134808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987-12-31</th>\n",
       "      <td>348.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-12-31</th>\n",
       "      <td>351.482453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-12-31</th>\n",
       "      <td>352.922308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-31</th>\n",
       "      <td>354.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-12-31</th>\n",
       "      <td>355.607885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-12-31</th>\n",
       "      <td>356.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-12-31</th>\n",
       "      <td>357.047885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-12-31</th>\n",
       "      <td>358.895283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-12-31</th>\n",
       "      <td>360.891923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-31</th>\n",
       "      <td>362.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-12-31</th>\n",
       "      <td>363.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-12-31</th>\n",
       "      <td>366.623462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>368.294231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-31</th>\n",
       "      <td>369.477736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-31</th>\n",
       "      <td>371.030769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-31</th>\n",
       "      <td>373.082115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-12-31</th>\n",
       "      <td>375.680816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>377.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-31</th>\n",
       "      <td>379.577551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>381.797200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-31</th>\n",
       "      <td>383.602549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>385.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>387.363269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-31</th>\n",
       "      <td>389.876346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31</th>\n",
       "      <td>391.649434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>394.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>396.560769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>398.610385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>400.877885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>404.276415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>407.841000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Using pandas to create Data Structures \n",
    "\n",
    "import pandas as pd\n",
    "filename = 'mlo_station_data_set/weekly_in_situ_co2_mlo.csv'\n",
    "data = pd.read_csv(filename, comment='\"',)\n",
    "data.columns = ['dates', 'co2_ppm']\n",
    "data['dates'] = pd.to_datetime(data['dates'])\n",
    "data.index = data['dates'] # A critical step for using resampling\n",
    "print(data)\n",
    "# Input is EASY, but computation is easier! Group data by year and compute the mean. Other functions: count(), sum(), median(), cumsum() etc. \n",
    "df2 = data.resample('A').mean()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pandas Grouping Options</h3>\n",
    "<p>There are many options for grouping. You can learn more about them in <a href=\"http://pandas.pydata.org/pandas-docs/stable/timeseries.html\">Pandas's timeseries docs </a>. They are also listed them below for your convience.</p>\n",
    "\n",
    "|  Value  |  Description  |\n",
    "|---------|:-------------:|\n",
    "|B | business day frequency | \n",
    "|C | custom business day frequency (experimental) |\n",
    "|D | calendar day frequency |\n",
    "|W | weekly frequency |\n",
    "|M | month end frequency |\n",
    "|BM | business month end frequency |\n",
    "|CBM | custom business month end frequency |\n",
    "|MS | month start frequency |\n",
    "|BMS | business month start frequency |\n",
    "|CBMS| custom business month start frequency |\n",
    "|Q | quarter end frequency |\n",
    "|BQ | business quarter endfrequency |\n",
    "|QS | quarter start frequency |\n",
    "|BQS | business quarter start frequency |\n",
    "|A | year end frequency |\n",
    "|BA | business year end frequency |\n",
    "|AS | year start frequency |\n",
    "|BAS | business year start frequency |\n",
    "|BH | business hour frequency |\n",
    "|H | hourly frequency |\n",
    "|T | minutely frequency |\n",
    "|S | secondly frequency |\n",
    "|L | milliseonds |\n",
    "|U | microseconds |\n",
    "|N | nanoseconds |\n",
    "\n",
    "\n",
    "<h3>Pandas Resampling Method Options</h3>\n",
    "<p>There are many methods you can apply on pandas dataframes. A non-comprehensive listed them below for your convience.</p>\n",
    "\n",
    "|  Method  |   Description   |\n",
    "|----------|:---------------:|\n",
    "| bfill | Backward fill |\n",
    "| count | Count of values |\n",
    "| ffill | Forward fill |\n",
    "| first | First valid data value |\n",
    "| last | Last valid data value |\n",
    "| max | Maximum data value |\n",
    "| mean | Mean of values in time range |\n",
    "| median | Median of values in time range |\n",
    "| min | Minimum data value |\n",
    "| nunique | Number of unique values |\n",
    "| ohlc | Opening value, highest value, lowest value, closing value |\n",
    "| pad | Same as forward fill |\n",
    "| std | Standard deviation of values |\n",
    "| sum | Sum of values |\n",
    "| var | Variance of values |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Writing Files with Pandas</h3>\n",
    "Here is the documentation for writing a csv file, locate the documentation for a json file on your own. https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Be careful as you write out functions- do not overwrite your original data.\n",
    "df2.to_csv('mlo_station_data_set/average_annual_co2.csv')\n",
    "\n",
    "#pandas.DataFrame.to_csv(path_or_buf=None, sep=', ', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Natural Science & Technology\n",
      "1      Social & Behavioral Sciences\n",
      "2      Natural Science & Technology\n",
      "3            Quantitative Reasoning\n",
      "4            Quantitative Reasoning\n",
      "5             Humanities & the Arts\n",
      "6      Social & Behavioral Sciences\n",
      "7            Quantitative Reasoning\n",
      "8      Natural Science & Technology\n",
      "8            Quantitative Reasoning\n",
      "9      Natural Science & Technology\n",
      "9            Quantitative Reasoning\n",
      "10     Natural Science & Technology\n",
      "11     Natural Science & Technology\n",
      "12     Social & Behavioral Sciences\n",
      "13           Quantitative Reasoning\n",
      "14           Quantitative Reasoning\n",
      "15     Natural Science & Technology\n",
      "16     Natural Science & Technology\n",
      "17           Quantitative Reasoning\n",
      "18     Natural Science & Technology\n",
      "19     Social & Behavioral Sciences\n",
      "20     Natural Science & Technology\n",
      "20           Quantitative Reasoning\n",
      "21     Natural Science & Technology\n",
      "21           Quantitative Reasoning\n",
      "22           Quantitative Reasoning\n",
      "23           Quantitative Reasoning\n",
      "24           Quantitative Reasoning\n",
      "25     Natural Science & Technology\n",
      "                   ...             \n",
      "469            Advanced Composition\n",
      "470             Non-Western Culture\n",
      "470          Quantitative Reasoning\n",
      "470    Social & Behavioral Sciences\n",
      "471           Humanities & the Arts\n",
      "472     Western/Comparative Culture\n",
      "472           Humanities & the Arts\n",
      "473           Humanities & the Arts\n",
      "474             Non-Western Culture\n",
      "474           Humanities & the Arts\n",
      "475          Quantitative Reasoning\n",
      "476            Advanced Composition\n",
      "477     Western/Comparative Culture\n",
      "477           Humanities & the Arts\n",
      "478     Western/Comparative Culture\n",
      "478           Humanities & the Arts\n",
      "479            Advanced Composition\n",
      "480     Western/Comparative Culture\n",
      "480           Humanities & the Arts\n",
      "481           Humanities & the Arts\n",
      "482           Humanities & the Arts\n",
      "483    Social & Behavioral Sciences\n",
      "484             Non-Western Culture\n",
      "484           Humanities & the Arts\n",
      "485            Advanced Composition\n",
      "485     Western/Comparative Culture\n",
      "485           Humanities & the Arts\n",
      "486    Social & Behavioral Sciences\n",
      "487     Western/Comparative Culture\n",
      "487           Humanities & the Arts\n",
      "Length: 698, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>avg_gpa</th>\n",
       "      <th>compre</th>\n",
       "      <th>pct_As</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenedRequirement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Advanced Composition</th>\n",
       "      <td>245.058824</td>\n",
       "      <td>3.422309</td>\n",
       "      <td>0.640070</td>\n",
       "      <td>0.424564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humanities &amp; the Arts</th>\n",
       "      <td>224.790323</td>\n",
       "      <td>3.357140</td>\n",
       "      <td>0.613929</td>\n",
       "      <td>0.388573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natural Science &amp; Technology</th>\n",
       "      <td>1355.483871</td>\n",
       "      <td>3.169332</td>\n",
       "      <td>0.588273</td>\n",
       "      <td>0.384213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Western Culture</th>\n",
       "      <td>216.828571</td>\n",
       "      <td>3.377348</td>\n",
       "      <td>0.632288</td>\n",
       "      <td>0.420239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantitative Reasoning</th>\n",
       "      <td>1254.686567</td>\n",
       "      <td>3.087739</td>\n",
       "      <td>0.554821</td>\n",
       "      <td>0.337707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social &amp; Behavioral Sciences</th>\n",
       "      <td>599.099099</td>\n",
       "      <td>3.333429</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.427871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western/Comparative Culture</th>\n",
       "      <td>292.858586</td>\n",
       "      <td>3.365834</td>\n",
       "      <td>0.625333</td>\n",
       "      <td>0.409208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fname = 'geneds_json.txt'\n",
    "data = pd.read_json(fname)\n",
    "s = data.apply(lambda x: pd.Series(x['GenedRequirement']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "print(s)\n",
    "s.name = 'GenedRequirement'\n",
    "new = data.drop('GenedRequirement', axis=1).join(s)\n",
    "new.groupby(['GenedRequirement']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
